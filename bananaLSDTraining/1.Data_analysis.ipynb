{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14069eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU name: Tesla V100-SXM2-32GB\n",
      "Total GPU mem (GB): 31.7325439453125\n",
      "timm version: 1.0.21\n",
      "PyTorch: 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, time, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, Subset, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "SEED = 42\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Total GPU mem (GB):\", torch.cuda.get_device_properties(0).total_memory / (1024**3))\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"timm version:\", timm.__version__)\n",
    "print(\"PyTorch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Config (edit before running) ----------\n",
    "DATA_DIR = Path(\"/home/23ucc611/Mini/data/BananaLSD\")       # where dataset will live after download/unzip\n",
    "USE_AUGMENTED = False                # we will use OriginalSetSetSetSet images and augment on-the-fly\n",
    "MODEL_NAME = \"resnetv2_50\"           # default choice: ResNetV2-50 (good balance & robust)\n",
    "IMG_SIZE = 224                       # image size for pretrained networks\n",
    "BATCH_SIZE = 64                      # conservative default; raise if GPU allows\n",
    "NUM_WORKERS = 8\n",
    "PIN_MEMORY = True\n",
    "SEED = 42\n",
    "\n",
    "# where to save training artifacts\n",
    "CHECKPOINT_DIR = Path(\"./checkpoints_bananalsd\")\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c387d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/23ucc611/Mini/data/BananaLSD/AugmentedSet\n",
      "/home/23ucc611/Mini/data/BananaLSD/OriginalSet\n",
      "Using image root: /home/23ucc611/Mini/data/BananaLSD/OriginalSet\n",
      "Class cordana: 162 images\n",
      "Class healthy: 129 images\n",
      "Class pestalotiopsis: 173 images\n",
      "Class sigatoka: 473 images\n",
      "Total images found under image root: 937\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for p in sorted(DATA_DIR.iterdir()):\n",
    "    print(p)\n",
    "\n",
    "# find image folders (look for 'OriginalSetSetSet' or a top-level folder with class subfolders)\n",
    "def find_image_root(base):\n",
    "    # try some heuristics\n",
    "    if (base/\"OriginalSet\").exists():\n",
    "        return base/\"OriginalSet\"\n",
    "    # otherwise, if there's a folder with class subfolders (images inside), return it\n",
    "    for child in base.iterdir():\n",
    "        if child.is_dir():\n",
    "            # check if this child contains further directories that look like classes\n",
    "            subdirs = [d for d in child.iterdir() if d.is_dir()]\n",
    "            if len(subdirs) >= 2:\n",
    "                return child\n",
    "    # fallback: base itself\n",
    "    return base\n",
    "\n",
    "img_root = find_image_root(DATA_DIR)\n",
    "print(\"Using image root:\", img_root)\n",
    "\n",
    "# count images per class if structure is like: img_root/class_name/*.jpg\n",
    "class_counts = {}\n",
    "for cls in sorted([d for d in img_root.iterdir() if d.is_dir()]):\n",
    "    cnt = len(list(cls.rglob(\"*.*\")))  # images under that folder\n",
    "    class_counts[cls.name] = cnt\n",
    "    print(f\"Class {cls.name}: {cnt} images\")\n",
    "\n",
    "total_images = sum(class_counts.values())\n",
    "print(\"Total images found under image root:\", total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19fc5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected classess :  ['cordana', 'healthy', 'pestalotiopsis', 'sigatoka']\n",
      "Total images (dataset_full) :  937\n",
      "Train Images :  843\n",
      "Val images :  94\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "infer_transform=T.Compose([\n",
    "    T.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
    "])\n",
    "\n",
    "train_transform=T.Compose([\n",
    "    T.RandomResizedCrop(IMG_SIZE,scale=(0.8,1.0)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandAugment(num_ops=2, magnitude=9),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
    "])\n",
    "\n",
    "dataset_full=ImageFolder(root=str(img_root),transform=train_transform)\n",
    "print(\"Detected classess : \",dataset_full.classes)\n",
    "print(\"Total images (dataset_full) : \",len(dataset_full))\n",
    "\n",
    "\n",
    "val_ratio=0.10\n",
    "val_size=int(math.ceil(len(dataset_full)*val_ratio))\n",
    "train_size=len(dataset_full)-val_size\n",
    "torch.manual_seed(SEED)\n",
    "train_ds,val_ds = random_split(dataset_full,[train_size,val_size])\n",
    "val_ds.dataset=ImageFolder(root=str(img_root),transform=infer_transform)\n",
    "\n",
    "print(\"Train Images : \",len(train_ds))\n",
    "print(\"Val images : \",len(val_ds))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536d3036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/23ucc611/Mini/data/BananaLSD/OriginalSet\n"
     ]
    }
   ],
   "source": [
    "print(img_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a6505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
