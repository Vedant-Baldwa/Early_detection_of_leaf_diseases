{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9adb7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/23ucc611/miniconda3/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU name: Tesla V100-SXM2-32GB\n",
      "Total GPU mem (GB): 31.7325439453125\n",
      "timm version: 1.0.21\n",
      "PyTorch: 2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import os, time, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\" \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None  \n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "SEED = 42\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Total GPU mem (GB):\", torch.cuda.get_device_properties(0).total_memory / (1024**3))\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"timm version:\", timm.__version__)\n",
    "print(\"PyTorch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c97bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "# ---- Config ----\n",
    "DATA_ROOT = Path(\"/home/23ucc611/Mini/data/BananaLSD\")        # <-- set to your dataset root (unzipped)\n",
    "MODEL_NAME = \"densenet201\"\n",
    "IMG_SIZE = 224\n",
    "\n",
    "BATCH_TRAIN = 64\n",
    "BATCH_EVAL  = 128\n",
    "NUM_WORKERS = 8\n",
    "PIN_MEMORY  = True\n",
    "SEED = 42\n",
    "\n",
    "# Training hyperparams\n",
    "EPOCHS = 130\n",
    "BASE_LR = 0.05          # base for batch=256; we scale with batch\n",
    "BATCH_LR_REF = 256.0\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "WARMUP_EPOCHS = 3\n",
    "MIN_LR = 1e-6\n",
    "\n",
    "# Regularization / goodies\n",
    "USE_MIXUP = True\n",
    "MIXUP_ALPHA = 0.8\n",
    "LABEL_SMOOTHING = 0.0    # not used if mixup on\n",
    "EMA_DECAY = 0.9999\n",
    "USE_AMP = True\n",
    "PRINT_FREQ = 50\n",
    "\n",
    "# Selection fraction for low-confidence images (20–25% as you asked)\n",
    "SELECT_PCT = 0.225      # 22.5% by default; set to 0.20–0.25\n",
    "\n",
    "# Paths for checkpoints and outputs\n",
    "OUT_DIR = Path(\"./bananalsd_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_DIR = OUT_DIR / \"checkpoints\"\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BEST_CKPT = CKPT_DIR / \"best_densenet201.pth\"\n",
    "BEST_M2_CKPT = CKPT_DIR / \"best_densenet201_retrained.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37a6b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using image root: /home/23ucc611/Mini/data/BananaLSD/AugmentedSet\n",
      "cordana             : 400\n",
      "healthy             : 400\n",
      "pestalotiopsis      : 400\n",
      "sigatoka            : 400\n",
      "Total images: 1600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_image_root(base: Path):\n",
    "    # Prefer \"original\" if present (we'll augment on-the-fly)\n",
    "    if (base / \"AugmentedSet\").exists():\n",
    "        return base / \"AugmentedSet\"\n",
    "    # else detect a folder that holds class subfolders\n",
    "    for child in base.iterdir():\n",
    "        if child.is_dir():\n",
    "            subdirs = [d for d in child.iterdir() if d.is_dir()]\n",
    "            if len(subdirs) >= 2:\n",
    "                return child\n",
    "    return base\n",
    "\n",
    "image_root = find_image_root(DATA_ROOT)\n",
    "print(\"Using image root:\", image_root)\n",
    "\n",
    "class_counts = {}\n",
    "for cls_dir in sorted([d for d in image_root.iterdir() if d.is_dir()]):\n",
    "    cnt = len(list(cls_dir.rglob(\"*.*\")))\n",
    "    class_counts[cls_dir.name] = cnt\n",
    "    print(f\"{cls_dir.name:20s}: {cnt}\")\n",
    "print(\"Total images:\", sum(class_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d820a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['cordana', 'healthy', 'pestalotiopsis', 'sigatoka']\n",
      "NUM_CLASSES: 4\n",
      "Train size: 1280  Val size: 320\n",
      "Batches -> Train: 20  Val: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tf = T.Compose([\n",
    "    T.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    # T.RandAugment(num_ops=2, magnitude=9),  # optional\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# Build an index-only dataset to get classes & deterministic indices\n",
    "index_ds = ImageFolder(root=str(image_root), transform=None)\n",
    "NUM_CLASSES = len(index_ds.classes)\n",
    "print(\"Classes:\", index_ds.classes)\n",
    "print(\"NUM_CLASSES:\", NUM_CLASSES)\n",
    "\n",
    "# Deterministic split indices (90/10)\n",
    "val_ratio = 0.20\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "perm = torch.randperm(len(index_ds), generator=g)\n",
    "val_size = max(1, int(math.ceil(len(index_ds) * val_ratio)))\n",
    "train_idx = perm[:-val_size].tolist()\n",
    "val_idx   = perm[-val_size:].tolist()\n",
    "\n",
    "# Build two base datasets with different transforms\n",
    "train_base = ImageFolder(root=str(image_root), transform=train_tf)\n",
    "val_base   = ImageFolder(root=str(image_root), transform=val_tf)\n",
    "\n",
    "# Subsets using the SAME indices (avoids label mix-ups)\n",
    "train_ds = Subset(train_base, train_idx)\n",
    "val_ds   = Subset(val_base,   val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_TRAIN, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "print(\"Train size:\", len(train_ds), \" Val size:\", len(val_ds))\n",
    "print(\"Batches -> Train:\", len(train_loader), \" Val:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd278d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet201: params=18,100,612, trainable=18,100,612\n",
      "Sanity forward OK. Logits shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — model (DenseNet-201), sanity forward\n",
    "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{MODEL_NAME}: params={total_params:,}, trainable={trainable_params:,}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    dummy = torch.zeros((1,3,IMG_SIZE,IMG_SIZE), device=DEVICE)\n",
    "    out = model(dummy)\n",
    "print(\"Sanity forward OK. Logits shape:\", tuple(out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbb1852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled base LR: 0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48994/854387316.py:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=autocast_enabled)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def one_hot(labels, num_classes, device, smoothing=0.0):\n",
    "    if smoothing > 0.0:\n",
    "        off = smoothing / (num_classes - 1)\n",
    "        on = 1.0 - smoothing\n",
    "    else:\n",
    "        off = 0.0; on = 1.0\n",
    "    y = torch.full((labels.size(0), num_classes), off, device=device)\n",
    "    y.scatter_(1, labels.unsqueeze(1), on)\n",
    "    return y\n",
    "\n",
    "def mixup_data(x, y, alpha=0.8, num_classes=None, device='cuda'):\n",
    "    if num_classes is None:\n",
    "        num_classes = NUM_CLASSES\n",
    "    if alpha <= 0:\n",
    "        return x, one_hot(y, num_classes, device, smoothing=0.0), 1.0, None\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0)).to(x.device)\n",
    "    x_mix = lam * x + (1 - lam) * x[idx]\n",
    "    y_a = one_hot(y, num_classes, device, smoothing=0.0)\n",
    "    y_b = one_hot(y[idx], num_classes, device, smoothing=0.0)\n",
    "    y_mix = lam * y_a + (1 - lam) * y_b\n",
    "    return x_mix, y_mix, lam, idx\n",
    "\n",
    "def soft_cross_entropy(logits, soft_targets):\n",
    "    logp = F.log_softmax(logits, dim=1)\n",
    "    return -(soft_targets * logp).sum(dim=1).mean()\n",
    "\n",
    "class ModelEMA:\n",
    "    def __init__(self, model, decay=0.9999, device='cpu'):\n",
    "        self.decay = decay\n",
    "        self.ema_model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=NUM_CLASSES)\n",
    "        self.ema_model.load_state_dict(model.state_dict())\n",
    "        for p in self.ema_model.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        self.ema_model.to(device)\n",
    "\n",
    "    def update(self, model):\n",
    "        with torch.no_grad():\n",
    "            msd = model.state_dict()\n",
    "            esd = self.ema_model.state_dict()\n",
    "            for k in esd.keys():\n",
    "                tgt = esd[k]\n",
    "                src = msd[k].to(tgt.device)\n",
    "                if tgt.dtype.is_floating_point:\n",
    "                    src = src.type_as(tgt)\n",
    "                    tgt.mul_(self.decay).add_(src, alpha=(1.0 - self.decay))\n",
    "                else:\n",
    "                    tgt.copy_(src)\n",
    "\n",
    "# Optimizer & LR schedule\n",
    "scaled_lr = BASE_LR * (BATCH_TRAIN / BATCH_LR_REF)\n",
    "print(\"Scaled base LR:\", scaled_lr)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=scaled_lr, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "from torch import amp\n",
    "autocast_enabled = (USE_AMP and DEVICE == 'cuda')\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=autocast_enabled)\n",
    "\n",
    "def get_lr(epoch, total_epochs=EPOCHS, warmup=WARMUP_EPOCHS, base_lr=scaled_lr, min_lr=MIN_LR):\n",
    "    if epoch < warmup:\n",
    "        return base_lr * float(epoch + 1) / float(max(1, warmup))\n",
    "    t = float(epoch - warmup) / float(max(1, total_epochs - warmup))\n",
    "    return min_lr + 0.5 * (base_lr - min_lr) * (1.0 + math.cos(math.pi * t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1323f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/130  lr=0.004167\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "No inf checks were recorded for this optimizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m autocast_enabled:\n\u001b[1;32m     43\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/torch/amp/grad_scaler.py:454\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m OptState\u001b[38;5;241m.\u001b[39mREADY:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n",
      "\u001b[0;31mAssertionError\u001b[0m: No inf checks were recorded for this optimizer."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "K_REPORT = 2\n",
    "ema = ModelEMA(model, decay=EMA_DECAY, device=DEVICE) if EMA_DECAY and EMA_DECAY > 0 else None\n",
    "\n",
    "\n",
    "\n",
    "best_val_top1 = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    cur_lr = get_lr(epoch)\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = cur_lr\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}  lr={cur_lr:.6f}\")\n",
    "\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    running_loss, seen = 0.0, 0\n",
    "    t0 = time.time()\n",
    "    for i, (imgs, targets) in enumerate(train_loader):\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        targets = targets.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        if USE_MIXUP:\n",
    "            inputs, soft_targets, _, _ = mixup_data(imgs, targets, alpha=MIXUP_ALPHA, num_classes=NUM_CLASSES, device=DEVICE)\n",
    "            loss_fn = soft_cross_entropy\n",
    "        else:\n",
    "            inputs = imgs\n",
    "            soft_targets = one_hot(targets, NUM_CLASSES, DEVICE, smoothing=LABEL_SMOOTHING)\n",
    "            loss_fn = soft_cross_entropy\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp.autocast('cuda', enabled=autocast_enabled):\n",
    "            logits = model(inputs)\n",
    "            loss = loss_fn(logits, soft_targets)\n",
    "\n",
    "        if autocast_enabled:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward(); optimizer.step()\n",
    "\n",
    "        if ema is not None:\n",
    "            ema.update(model)\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        running_loss += float(loss.item()) * bs\n",
    "        seen += bs\n",
    "\n",
    "        if (i+1) % PRINT_FREQ == 0 or (i+1) == len(train_loader):\n",
    "            print(f\"Epoch {epoch+1} Batch {i+1}/{len(train_loader)}  AvgLoss: {running_loss/seen:.4f}  Time: {time.time()-t0:.1f}s\")\n",
    "\n",
    "    # ---- Validate (use EMA if available) ----\n",
    "    eval_model = ema.ema_model if ema is not None else model\n",
    "    eval_model.eval()\n",
    "\n",
    "    val_total = 0\n",
    "    top1_correct = 0\n",
    "    topk_correct = 0\n",
    "    val_loss_sum = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in val_loader:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            targets = targets.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            logits = eval_model(imgs)\n",
    "            loss_v = F.cross_entropy(logits, targets)\n",
    "            val_loss_sum += float(loss_v.item()) * imgs.size(0)\n",
    "\n",
    "            # Top-1\n",
    "            _, pred1 = logits.max(dim=1)\n",
    "            top1_correct += (pred1 == targets).sum().item()\n",
    "\n",
    "            # Top-K only if K_REPORT >= 2\n",
    "            if K_REPORT >= 2:\n",
    "                _, predk = logits.topk(K_REPORT, dim=1, largest=True, sorted=True)\n",
    "                topk_correct += (predk == targets.view(-1,1)).any(dim=1).sum().item()\n",
    "\n",
    "            val_total += imgs.size(0)\n",
    "\n",
    "    val_top1 = 100.0 * top1_correct / val_total\n",
    "    val_loss = val_loss_sum / val_total\n",
    "    msg = f\"Epoch {epoch+1} VAL -> Loss: {val_loss:.4f}  Top1: {val_top1:.3f}\"\n",
    "    if K_REPORT >= 2:\n",
    "        val_topk = 100.0 * topk_correct / val_total\n",
    "        msg += f\"  Top{K_REPORT}: {val_topk:.3f}\"\n",
    "    print(msg)\n",
    "\n",
    "    # save checkpoint and best\n",
    "    state = {\n",
    "        \"epoch\": epoch+1,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"val_top1\": val_top1,\n",
    "        \"cfg\": {\"MODEL_NAME\": MODEL_NAME, \"IMG_SIZE\": IMG_SIZE, \"NUM_CLASSES\": NUM_CLASSES}\n",
    "    }\n",
    "    if val_top1 > best_val_top1:\n",
    "        best_val_top1 = val_top1\n",
    "        torch.save(state, BEST_CKPT)\n",
    "        print(f\"Saved BEST to {str(BEST_CKPT)} (ValTop1={val_top1:.3f})\")\n",
    "\n",
    "print(\"Training complete. Best Val Top1:\", best_val_top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09552975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL EVAL -> Top1: 99.938  Top2: 100.000\n",
      "Saved per-image CSV: bananalsd_outputs/predictions_bananalsd_full.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — FULL DATASET EVAL (all images), save per-image CSV\n",
    "class ImageFolderWithPaths(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super().__getitem__(index)\n",
    "        path, _ = self.samples[index]\n",
    "        return img, target, path\n",
    "\n",
    "eval_tf = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "full_ds_wp = ImageFolderWithPaths(root=str(image_root), transform=eval_tf)\n",
    "NUM_CLASSES = len(full_ds_wp.classes)\n",
    "K_REPORT = 2\n",
    "full_loader = DataLoader(full_ds_wp, batch_size=BATCH_EVAL, shuffle=False,\n",
    "                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "# load best\n",
    "ck = torch.load(str(BEST_CKPT), map_location=DEVICE)\n",
    "state_dict = ck.get(\"model_state\", ck)\n",
    "state_dict = {k.replace(\"module.\",\"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "eval_model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "eval_model.load_state_dict(state_dict)\n",
    "eval_model.eval()\n",
    "\n",
    "total = 0\n",
    "top1_correct = 0\n",
    "topk_correct = 0\n",
    "rows = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, targets, paths in full_loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        targets = targets.to(DEVICE, non_blocking=True)\n",
    "        logits = eval_model(imgs)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        top1_prob, pred1 = probs.max(dim=1)\n",
    "\n",
    "        # metrics\n",
    "        top1_correct += (pred1 == targets).sum().item()\n",
    "        if K_REPORT >= 2:\n",
    "            _, predk = probs.topk(K_REPORT, dim=1, largest=True, sorted=True)\n",
    "            topk_correct += (predk == targets.view(-1,1)).any(dim=1).sum().item()\n",
    "        total += imgs.size(0)\n",
    "\n",
    "        # rows for CSV\n",
    "        t_np = targets.cpu().numpy()\n",
    "        p_np = pred1.cpu().numpy()\n",
    "        c_np = top1_prob.cpu().numpy()\n",
    "        for pth, t, p, c in zip(paths, t_np, p_np, c_np):\n",
    "            rows.append({\"path\": pth, \"true_label\": int(t), \"pred_label\": int(p), \"top1_prob\": float(c)})\n",
    "\n",
    "top1 = 100.0 * top1_correct / total\n",
    "print(f\"FULL EVAL -> Top1: {top1:.3f}\", end=\"\")\n",
    "if K_REPORT >= 2:\n",
    "    topk = 100.0 * topk_correct / total\n",
    "    print(f\"  Top{K_REPORT}: {topk:.3f}\")\n",
    "else:\n",
    "    print()\n",
    "\n",
    "pred_csv_path = OUT_DIR / \"predictions_bananalsd_full.csv\"\n",
    "pd.DataFrame(rows).to_csv(pred_csv_path, index=False)\n",
    "print(\"Saved per-image CSV:\", pred_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
