{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0820ba61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]\n",
      "torch: 2.6.0+cu124\n",
      "torchvision: 0.21.0+cu124\n",
      "Device: cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os, math, random\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\" \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, random_split, ConcatDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "print(\"python:\", os.sys.version.splitlines()[0])\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d17960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"./data\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_PRED = 256\n",
    "NUM_WORKERS = 8\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"resnext101_32x8d\"\n",
    "BEST_CKPT = os.path.join(\"m2_retrained_checkpoints/best_m2_retrained.pth\")\n",
    "SAVE_CSV = \"predictions_60k_m2.csv\"\n",
    "SAVE_FULL_PROBS = False\n",
    "SAVE_FULL_PROBS_PATH = \"full_probs_60k_m2.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0102e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes -> train: 50000  test: 10000  total: 60000\n"
     ]
    }
   ],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "infer_transform = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# build concat dataset (train then test) - matches the ordering used earlier\n",
    "train_ds = datasets.CIFAR100(root=DATA_ROOT, train=True, download=False, transform=infer_transform)\n",
    "test_ds  = datasets.CIFAR100(root=DATA_ROOT, train=False, download=False, transform=infer_transform)\n",
    "concat_ds = ConcatDataset([train_ds, test_ds])\n",
    "len_train = len(train_ds)\n",
    "len_test = len(test_ds)\n",
    "print(\"Dataset sizes -> train:\", len_train, \" test:\", len_test, \" total:\", len(concat_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41c7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/23ucc611/miniconda3/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint weights into model. Starting inference...\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "pred_loader = DataLoader(concat_ds, batch_size=BATCH_PRED, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# create model and load checkpoint\n",
    "model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=100)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "if not os.path.exists(BEST_CKPT):\n",
    "    raise RuntimeError(f\"Checkpoint not found at: {BEST_CKPT}\")\n",
    "\n",
    "ck = torch.load(BEST_CKPT, map_location=DEVICE)\n",
    "\n",
    "if isinstance(ck, dict) and \"model_state\" in ck:\n",
    "    state_dict = ck[\"model_state\"]\n",
    "elif isinstance(ck, dict) and \"state_dict\" in ck:\n",
    "    state_dict = ck[\"state_dict\"]\n",
    "elif isinstance(ck, dict) and any(k.startswith(\"module.\") or k in model.state_dict().keys() for k in ck.keys()):\n",
    "    state_dict = ck\n",
    "else:\n",
    "    state_dict = ck\n",
    "\n",
    "\n",
    "new_state = {}\n",
    "for k, v in state_dict.items():\n",
    "    new_k = k\n",
    "    if k.startswith(\"module.\"):\n",
    "        new_k = k[len(\"module.\"):]\n",
    "    new_state[new_k] = v\n",
    "model.load_state_dict(new_state)\n",
    "model.eval()\n",
    "print(\"Loaded checkpoint weights into model. Starting inference...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071826a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference done in 337.7s over 60000 samples\n",
      "Final results over full 60k -> Top1: 97.750  Top5: 99.785\n",
      "Saved per-image predictions CSV: predictions_60k_m2.csv\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "import time\n",
    "rows = []\n",
    "probs_accum = [] if SAVE_FULL_PROBS else None\n",
    "\n",
    "start_idx = 0\n",
    "total_top1_correct = 0\n",
    "total_top5_correct = 0\n",
    "total_samples = 0\n",
    "t0 = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in pred_loader:\n",
    "        bs = imgs.size(0)\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        logits = model(imgs)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        top1_probs, top1_preds = probs.max(dim=1)\n",
    "\n",
    "        _, top5_preds = probs.topk(5, dim=1, largest=True, sorted=True)  # [B,5]\n",
    "\n",
    "        total_top1_correct += (top1_preds == labels).sum().item()\n",
    "\n",
    "        correct_top5_batch = top5_preds.eq(labels.view(-1,1).expand_as(top5_preds)).any(dim=1).sum().item()\n",
    "        total_top5_correct += correct_top5_batch\n",
    "\n",
    "        top1p_np = top1_probs.cpu().numpy()\n",
    "        top1preds_np = top1_preds.cpu().numpy()\n",
    "        labels_np = labels.cpu().numpy()\n",
    "\n",
    "        for i in range(bs):\n",
    "            global_idx = start_idx + i\n",
    "            if global_idx < len_train:\n",
    "                origin = \"train\"\n",
    "                orig_index = global_idx\n",
    "            else:\n",
    "                origin = \"test\"\n",
    "                orig_index = global_idx - len_train\n",
    "\n",
    "            rows.append({\n",
    "                \"global_idx\": int(global_idx),\n",
    "                \"set\": origin,\n",
    "                \"orig_index\": int(orig_index),\n",
    "                \"true_label\": int(labels_np[i]),\n",
    "                \"pred_label\": int(top1preds_np[i]),\n",
    "                \"top1_prob\": float(top1p_np[i])\n",
    "            })\n",
    "\n",
    "        if SAVE_FULL_PROBS:\n",
    "            probs_accum.append(probs.cpu().numpy())\n",
    "\n",
    "        start_idx += bs\n",
    "        total_samples += bs\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "top1_acc = 100.0 * total_top1_correct / total_samples\n",
    "top5_acc = 100.0 * total_top5_correct / total_samples\n",
    "\n",
    "print(f\"Inference done in {elapsed:.1f}s over {total_samples} samples\")\n",
    "print(f\"Final results over full 60k -> Top1: {top1_acc:.3f}  Top5: {top5_acc:.3f}\")\n",
    "\n",
    "# save CSV\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(SAVE_CSV, index=False)\n",
    "print(\"Saved per-image predictions CSV:\", SAVE_CSV)\n",
    "\n",
    "if SAVE_FULL_PROBS:\n",
    "    all_probs = np.vstack(probs_accum)\n",
    "    np.savez_compressed(SAVE_FULL_PROBS_PATH, probs=all_probs)\n",
    "    print(\"Saved full probs NPZ:\", SAVE_FULL_PROBS_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
