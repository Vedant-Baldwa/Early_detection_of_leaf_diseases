# -*- coding: utf-8 -*-
"""CNN-notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19clUKwww04e3n_YpgU76gqQ6Z5kpNIHD
"""

import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import pickle
import shap
import os


from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV
from sklearn.linear_model import LinearRegression , Ridge , Lasso, LogisticRegression
from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer, OneHotEncoder, FunctionTransformer, PolynomialFeatures, MaxAbsScaler, MinMaxScaler
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,StackingRegressor, StackingClassifier, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.svm import SVR, SVC
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.feature_selection import SelectKBest, f_regression, f_classif, SelectFromModel
from xgboost import XGBClassifier,XGBRegressor, plot_importance
from sklearn.metrics import mean_squared_error, r2_score,accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.base import BaseEstimator, TransformerMixin

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D


import warnings
warnings.filterwarnings('ignore')



from google.colab import drive
if not os.path.exists('/content/drive'):
    drive.mount('/content/drive')

(x_train,y_train),(x_test,y_test)=tf.keras.datasets.cifar100.load_data(label_mode='fine')
y_train=y_train.ravel()
y_test=y_test.ravel()

x_train=x_train.astype(np.float32)/255.0;
x_test=x_test.astype(np.float32)/255.0;

print(f"X_train shape : {x_train.shape} , Y_train shape : {y_train.shape}")
print(f"X_test shape : {x_test.shape} , Y_test shape : {y_test.shape}")

x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=0.1,stratify=y_train,random_state=24)

print(f"X_train shape : {x_train.shape} , Y_train shape : {y_train.shape}")
print(f"X_val shape : {x_val.shape} , Y_val shape : {y_val.shape}")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

batch_size = 128

train_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)

import tensorflow as tf
from tensorflow.keras import layers,models


def build_custom_cnn(input_shape=(32,32,3),num_classes=100):
    inp=layers.Input(shape=input_shape)


    x=layers.Conv2D(32,(3,3),padding='same',use_bias=False)(inp)
    x=layers.BatchNormalization()(x)
    x=layers.ReLU()(x)
    x=layers.Conv2D(32,(3,3),padding='same',use_bias=False)(x)
    x=layers.BatchNormalization()(x)
    x=layers.ReLU()(x)
    x=layers.MaxPooling2D((2,2))(x)
    x=layers.Dropout(0.2)(x)


    x=layers.Conv2D(64,(3,3),padding='same',use_bias=False)(x)
    x=layers.BatchNormalization()(x)
    x=layers.ReLU()(x)
    x=layers.Conv2D(64,(3,3),padding='same',use_bias=False)(x)
    x=layers.BatchNormalization()(x)
    x=layers.ReLU()(x)
    x=layers.MaxPooling2D((2,2))(x)
    x=layers.Dropout(0.3)(x)

    x=layers.Conv2D(128,(3,3),padding='same',use_bias=False)(x)
    x=layers.BatchNormalization()(x)
    x=layers.ReLU()(x)
    x=layers.Conv2D(128,(3,3),padding='same',use_bias=False)(x)
    x=layers.BatchNormalization()(x)
    x=layers.ReLU()(x)
    x=layers.MaxPooling2D((2,2))(x)
    x=layers.Dropout(0.4)(x)

    x=layers.GlobalAveragePooling2D()(x)
    x=layers.Dense(512,use_bias=False)(x)
    x=layers.BatchNormalization()(x)
    x=layers.ReLU()(x)
    x=layers.Dropout(0.5)(x)
    out=layers.Dense(num_classes,activation='softmax')(x)

    return models.Model(inp,out)

input_shape=x_train.shape[1:]
model=build_custom_cnn(input_shape)
model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='sparse_categorical_crossentropy',metrics=['accuracy'])

from tensorflow.keras import callbacks

es=callbacks.EarlyStopping(monitor='val_loss',patience=8,restore_best_weights=True,verbose=1)
mc=callbacks.ModelCheckpoint('best_custom_cnn.h5',monitor='val_loss',save_best_only=True,verbose=1)
rlr=callbacks.ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.5,verbose=1)

csv_logger=callbacks.CSVLogger('training_log.csv')

epochs = 60
steps_per_epoch = max(1, x_train.shape[0] // batch_size)

history = model.fit(
    train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=(x_val, y_val),
    callbacks=[es, mc, rlr, csv_logger]
)

import matplotlib.pyplot as plt

def plot_history(history):
    hist = history.history
    plt.figure(figsize=(12,4))
    plt.subplot(1,2,1)
    plt.plot(hist['loss'], label='train loss')
    plt.plot(hist['val_loss'], label='val loss')
    plt.legend(); plt.title('Loss')
    plt.subplot(1,2,2)
    plt.plot(hist['accuracy'], label='train acc')
    plt.plot(hist['val_accuracy'], label='val acc')
    plt.legend(); plt.title('Accuracy')
    plt.show()

plot_history(history)

model.load_weights('best_custom_cnn.h5')
test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=128, verbose=2)
print(f"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}")

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

y_pred_probs = model.predict(x_test, batch_size=256, verbose=1)
y_pred = np.argmax(y_pred_probs, axis=1)

print(classification_report(y_test, y_pred, digits=3))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
plt.imshow(cm, interpolation='nearest')
plt.title('Confusion matrix')
plt.colorbar()
plt.show()

model.save('custom_cnn_cifar100_full.h5')
model.save('custom_cnn_cifar100_savedmodel')